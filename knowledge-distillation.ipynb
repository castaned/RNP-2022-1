{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-18T10:25:52.520446Z",
     "iopub.status.busy": "2021-12-18T10:25:52.520120Z",
     "iopub.status.idle": "2021-12-18T10:25:56.948991Z",
     "shell.execute_reply": "2021-12-18T10:25:56.948157Z",
     "shell.execute_reply.started": "2021-12-18T10:25:52.520370Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:25:56.951187Z",
     "iopub.status.busy": "2021-12-18T10:25:56.950920Z",
     "iopub.status.idle": "2021-12-18T10:26:03.263098Z",
     "shell.execute_reply": "2021-12-18T10:26:03.262373Z",
     "shell.execute_reply.started": "2021-12-18T10:25:56.951153Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255.0\n",
    "x_valid = x_valid/255.0\n",
    "# x_train = np.expand_dims(x_train, axis=3)\n",
    "# x_valid = np.expand_dims(x_valid, axis=3)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_valid = keras.utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:03.264760Z",
     "iopub.status.busy": "2021-12-18T10:26:03.264510Z",
     "iopub.status.idle": "2021-12-18T10:26:03.273839Z",
     "shell.execute_reply": "2021-12-18T10:26:03.273204Z",
     "shell.execute_reply.started": "2021-12-18T10:26:03.264728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3), 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_EPOCHS = 25\n",
    "S_EPOCHS = 20\n",
    "IMAGE_SIZE = x_train.shape[1:]\n",
    "BATCH_SIZE = 512\n",
    "N_CLASSES = y_train.shape[-1]\n",
    "IMAGE_SIZE, N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:03.275635Z",
     "iopub.status.busy": "2021-12-18T10:26:03.275174Z",
     "iopub.status.idle": "2021-12-18T10:26:03.287140Z",
     "shell.execute_reply": "2021-12-18T10:26:03.286353Z",
     "shell.execute_reply.started": "2021-12-18T10:26:03.275603Z"
    }
   },
   "outputs": [],
   "source": [
    "def nn_callbacks():\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        patience=5, verbose=1, restore_best_weights=True, min_delta=1e-4\n",
    "    )\n",
    "    rlp = keras.callbacks.ReduceLROnPlateau(patience=2, verbose=1)\n",
    "    return [es, rlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:03.291255Z",
     "iopub.status.busy": "2021-12-18T10:26:03.290772Z",
     "iopub.status.idle": "2021-12-18T10:26:06.683984Z",
     "shell.execute_reply": "2021-12-18T10:26:06.683318Z",
     "shell.execute_reply.started": "2021-12-18T10:26:03.291228Z"
    }
   },
   "outputs": [],
   "source": [
    "d_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "d_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "\n",
    "del x_train, x_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teacher Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:06.685666Z",
     "iopub.status.busy": "2021-12-18T10:26:06.685143Z",
     "iopub.status.idle": "2021-12-18T10:26:07.860740Z",
     "shell.execute_reply": "2021-12-18T10:26:07.860029Z",
     "shell.execute_reply.started": "2021-12-18T10:26:06.685624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 20,029,514\n",
      "Trainable params: 20,029,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_teacher_model(name='teacher'):\n",
    "    base_model = keras.applications.VGG19(input_shape=IMAGE_SIZE, include_top=False)\n",
    "    base_model.trainable = True\n",
    "    return keras.models.Sequential([\n",
    "            base_model,        \n",
    "            L.GlobalAvgPool2D(),        \n",
    "            L.Dense(N_CLASSES)\n",
    "        ], name=name\n",
    "    )\n",
    "        \n",
    "\n",
    "teacher_model = build_teacher_model()\n",
    "teacher_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:07.862081Z",
     "iopub.status.busy": "2021-12-18T10:26:07.861842Z",
     "iopub.status.idle": "2021-12-18T10:26:08.024919Z",
     "shell.execute_reply": "2021-12-18T10:26:08.024230Z",
     "shell.execute_reply.started": "2021-12-18T10:26:07.862048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"student\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 519,434\n",
      "Trainable params: 519,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_student_model(name='student'):\n",
    "    return keras.models.Sequential([\n",
    "        L.Conv2D(64, 3, input_shape=IMAGE_SIZE, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.GlobalAvgPool2D(),\n",
    "        L.Dense(N_CLASSES),\n",
    "    ],name=name) \n",
    "\n",
    "student_model = build_student_model()\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:08.027495Z",
     "iopub.status.busy": "2021-12-18T10:26:08.027255Z",
     "iopub.status.idle": "2021-12-18T10:30:55.509112Z",
     "shell.execute_reply": "2021-12-18T10:30:55.508391Z",
     "shell.execute_reply.started": "2021-12-18T10:26:08.027465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "98/98 [==============================] - 17s 87ms/step - loss: 1.8074 - accuracy: 0.3681 - val_loss: 0.9637 - val_accuracy: 0.6598\n",
      "Epoch 2/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.8992 - accuracy: 0.6852 - val_loss: 0.7873 - val_accuracy: 0.7226\n",
      "Epoch 3/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.7416 - accuracy: 0.7420 - val_loss: 0.7197 - val_accuracy: 0.7498\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6542 - accuracy: 0.7736 - val_loss: 0.6868 - val_accuracy: 0.7594\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.5971 - accuracy: 0.7927 - val_loss: 0.6464 - val_accuracy: 0.7734\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.5408 - accuracy: 0.8139 - val_loss: 0.6257 - val_accuracy: 0.7819\n",
      "Epoch 7/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.5035 - accuracy: 0.8250 - val_loss: 0.6245 - val_accuracy: 0.7864\n",
      "Epoch 8/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.4702 - accuracy: 0.8372 - val_loss: 0.6045 - val_accuracy: 0.7940\n",
      "Epoch 9/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.4334 - accuracy: 0.8498 - val_loss: 0.5898 - val_accuracy: 0.7987\n",
      "Epoch 10/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.4080 - accuracy: 0.8616 - val_loss: 0.6071 - val_accuracy: 0.7938\n",
      "Epoch 11/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.3784 - accuracy: 0.8706 - val_loss: 0.5775 - val_accuracy: 0.8036\n",
      "Epoch 12/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.3534 - accuracy: 0.8790 - val_loss: 0.5842 - val_accuracy: 0.8023\n",
      "Epoch 13/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.3324 - accuracy: 0.8873 - val_loss: 0.5854 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 14/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.2919 - accuracy: 0.9041 - val_loss: 0.5638 - val_accuracy: 0.8118\n",
      "Epoch 15/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.2763 - accuracy: 0.9094 - val_loss: 0.5655 - val_accuracy: 0.8123\n",
      "Epoch 16/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.2715 - accuracy: 0.9114 - val_loss: 0.5683 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 17/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.2659 - accuracy: 0.9134 - val_loss: 0.5663 - val_accuracy: 0.8133\n",
      "Epoch 18/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.2644 - accuracy: 0.9138 - val_loss: 0.5664 - val_accuracy: 0.8131\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 19/25\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.2618 - accuracy: 0.9153 - val_loss: 0.5660 - val_accuracy: 0.8133\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "teacher_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5), \n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = teacher_model.fit(\n",
    "    d_train.shuffle(1024, 19).batch(BATCH_SIZE),\n",
    "    validation_data=d_valid.shuffle(1024, 19).batch(BATCH_SIZE),\n",
    "    epochs=T_EPOCHS,\n",
    "    callbacks=nn_callbacks(), \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:30:55.515237Z",
     "iopub.status.busy": "2021-12-18T10:30:55.513336Z",
     "iopub.status.idle": "2021-12-18T10:30:55.540057Z",
     "shell.execute_reply": "2021-12-18T10:30:55.539143Z",
     "shell.execute_reply.started": "2021-12-18T10:30:55.515193Z"
    }
   },
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher, activation):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.activation = activation\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=10,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student.compile(optimizer=optimizer, metrics=metrics, loss=student_loss_fn)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                self.activation(teacher_predictions / self.temperature, axis=1),\n",
    "                self.activation(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, \"loss\": loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        student_predictions = self.student(x, training=False)\n",
    "        \n",
    "        student_loss = self.student_loss_fn(y, student_predictions)\n",
    "        distillation_loss = self.distillation_loss_fn(\n",
    "            self.activation(teacher_predictions / self.temperature, axis=1),\n",
    "            self.activation(student_predictions / self.temperature, axis=1),\n",
    "        )\n",
    "        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "        \n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, \"loss\": loss}\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.student(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-18T10:30:55.544466Z",
     "iopub.status.busy": "2021-12-18T10:30:55.543752Z",
     "iopub.status.idle": "2021-12-18T10:34:30.124781Z",
     "shell.execute_reply": "2021-12-18T10:34:30.124002Z",
     "shell.execute_reply.started": "2021-12-18T10:30:55.544429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 7s 63ms/step - accuracy: 0.1640 - student_loss: 2.0546 - distillation_loss: 1.6996 - loss: 1.9481 - val_accuracy: 0.3367 - val_student_loss: 1.8224 - val_distillation_loss: 1.3935 - val_loss: 1.6937\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.3414 - student_loss: 1.6584 - distillation_loss: 1.3019 - loss: 1.5514 - val_accuracy: 0.3551 - val_student_loss: 1.7123 - val_distillation_loss: 1.2791 - val_loss: 1.5823\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.4274 - student_loss: 1.4588 - distillation_loss: 1.1035 - loss: 1.3522 - val_accuracy: 0.4858 - val_student_loss: 1.3996 - val_distillation_loss: 0.9772 - val_loss: 1.2729\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.5177 - student_loss: 1.2812 - distillation_loss: 0.9312 - loss: 1.1762 - val_accuracy: 0.5436 - val_student_loss: 1.3165 - val_distillation_loss: 0.9392 - val_loss: 1.2033\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.5659 - student_loss: 1.1521 - distillation_loss: 0.8114 - loss: 1.0499 - val_accuracy: 0.5988 - val_student_loss: 1.0578 - val_distillation_loss: 0.7750 - val_loss: 0.9730\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.6262 - student_loss: 1.0117 - distillation_loss: 0.6853 - loss: 0.9138 - val_accuracy: 0.6344 - val_student_loss: 1.0405 - val_distillation_loss: 0.6971 - val_loss: 0.9375\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.6633 - student_loss: 0.9163 - distillation_loss: 0.6044 - loss: 0.8227 - val_accuracy: 0.6559 - val_student_loss: 1.1711 - val_distillation_loss: 0.7433 - val_loss: 1.0427\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.6904 - student_loss: 0.8400 - distillation_loss: 0.5457 - loss: 0.7517 - val_accuracy: 0.6892 - val_student_loss: 0.8985 - val_distillation_loss: 0.6350 - val_loss: 0.8195\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.7223 - student_loss: 0.7731 - distillation_loss: 0.4942 - loss: 0.6894 - val_accuracy: 0.7039 - val_student_loss: 0.9081 - val_distillation_loss: 0.6086 - val_loss: 0.8182\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.7450 - student_loss: 0.7064 - distillation_loss: 0.4495 - loss: 0.6293 - val_accuracy: 0.6951 - val_student_loss: 0.8882 - val_distillation_loss: 0.5757 - val_loss: 0.7945\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.7585 - student_loss: 0.6572 - distillation_loss: 0.4160 - loss: 0.5849 - val_accuracy: 0.7190 - val_student_loss: 0.7471 - val_distillation_loss: 0.5581 - val_loss: 0.6904\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.7783 - student_loss: 0.6099 - distillation_loss: 0.3867 - loss: 0.5430 - val_accuracy: 0.7358 - val_student_loss: 0.6813 - val_distillation_loss: 0.4874 - val_loss: 0.6231\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.8031 - student_loss: 0.5522 - distillation_loss: 0.3500 - loss: 0.4915 - val_accuracy: 0.7400 - val_student_loss: 0.7635 - val_distillation_loss: 0.5580 - val_loss: 0.7018\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.8164 - student_loss: 0.5120 - distillation_loss: 0.3325 - loss: 0.4581 - val_accuracy: 0.7467 - val_student_loss: 0.6311 - val_distillation_loss: 0.4430 - val_loss: 0.5747\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.8361 - student_loss: 0.4552 - distillation_loss: 0.3040 - loss: 0.4098 - val_accuracy: 0.7502 - val_student_loss: 0.8263 - val_distillation_loss: 0.5273 - val_loss: 0.7366\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.8430 - student_loss: 0.4371 - distillation_loss: 0.3022 - loss: 0.3966 - val_accuracy: 0.7454 - val_student_loss: 0.6659 - val_distillation_loss: 0.5159 - val_loss: 0.6209\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.8708 - student_loss: 0.3407 - distillation_loss: 0.2502 - loss: 0.3135 - val_accuracy: 0.7828 - val_student_loss: 0.6576 - val_distillation_loss: 0.5198 - val_loss: 0.6162\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.8980 - student_loss: 0.2992 - distillation_loss: 0.2365 - loss: 0.2804 - val_accuracy: 0.7848 - val_student_loss: 0.7371 - val_distillation_loss: 0.4889 - val_loss: 0.6627\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 6s 60ms/step - accuracy: 0.9057 - student_loss: 0.2791 - distillation_loss: 0.2316 - loss: 0.2648 - val_accuracy: 0.7863 - val_student_loss: 0.7120 - val_distillation_loss: 0.5634 - val_loss: 0.6674\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "distiller = Distiller(student_model, teacher_model, tf.nn.softmax)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'],\n",
    "    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.7,\n",
    "    temperature=1,\n",
    ")\n",
    "history_distillation = distiller.fit(\n",
    "    d_train.shuffle(1024, 19).batch(BATCH_SIZE), \n",
    "    validation_data=d_valid.shuffle(1024, 19).batch(BATCH_SIZE),\n",
    "    epochs=S_EPOCHS, callbacks=nn_callbacks(), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:34:30.126439Z",
     "iopub.status.busy": "2021-12-18T10:34:30.126155Z",
     "iopub.status.idle": "2021-12-18T10:34:32.867598Z",
     "shell.execute_reply": "2021-12-18T10:34:32.866840Z",
     "shell.execute_reply.started": "2021-12-18T10:34:30.126404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model:\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 0.5638 - accuracy: 0.8118\n",
      "File Size is : 229.35 MB\n",
      "Distilled Model:\n",
      "20/20 [==============================] - 1s 16ms/step - loss: 0.7436 - accuracy: 0.7495\n",
      "File Size is : 6.09 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('Teacher Model:')\n",
    "teacher_model.save('teacher.h5')\n",
    "teacher_model.evaluate(d_valid.shuffle(1024, 19).batch(BATCH_SIZE))\n",
    "print(\"File Size is :\", round(os.path.getsize('teacher.h5')/1024**2, 2), \"MB\")\n",
    "print('Distilled Model:')\n",
    "student_model.save('student.h5')\n",
    "student_model.evaluate(d_valid.shuffle(1024, 19).batch(BATCH_SIZE))\n",
    "print(\"File Size is :\", round(os.path.getsize('student.h5')/1024**2, 2), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**\n",
    "\n",
    "* [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)\n",
    "* [Implementation of classical Knowledge Distillation](https://keras.io/examples/vision/knowledge_distillation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
